# G検定勉強メモ

- [G検定勉強メモ](#g検定勉強メモ)
  - [人工知能とは](#人工知能とは)
    - [人工知能の定義](#人工知能の定義)
    - [人工知能分野で議論される問題](#人工知能分野で議論される問題)
  - [人工知能をめぐる動向](#人工知能をめぐる動向)
    - [探索と推論](#探索と推論)
    - [知識表現とエキスパートシステム](#知識表現とエキスパートシステム)
    - [機械学習](#機械学習)
    - [ディープラーニング](#ディープラーニング)
  - [機械学習の概要](#機械学習の概要)
    - [教師あり学習](#教師あり学習)
    - [教師なし学習](#教師なし学習)
    - [強化学習](#強化学習)
    - [モデルの選択と評価](#モデルの選択と評価)
  - [ディープラーニングの概要](#ディープラーニングの概要)
    - [ニューラルネットワークとディープラーニング](#ニューラルネットワークとディープラーニング)
    - [誤差関数](#誤差関数)
    - [正則化](#正則化)
    - [最適化手法](#最適化手法)
    - [誤差逆伝播法](#誤差逆伝播法)

---

## 人工知能とは

### 人工知能の定義

- **AI効果**  
  AI技術の進展により、AIで新しいことが実現され、その原理がわかると、「それは単なる自動化であり、知能とは関係ない」と見なされる心理的効果。この現象を「AI効果」と呼ぶ。

- **人工知能のレベル**  
  1. **単純な制御プログラム** - すべての振る舞いが事前に決められているプログラム。自動ドアの開閉や信号機の制御など、ルール通りに動作する。  
  2. **古典的な人工知能** - 探索や推論、知識データベースを活用し、状況に応じた複雑な振る舞いができる。チェスのように、勝つための最適な手を探索するプログラムが例。  
  3. **機械学習を取り入れた人工知能** - 多くのサンプルデータをもとに、入力と出力の関係を学習するもの。画像認識や音声認識のように、データから学んだパターンで判断を行う。  
  4. **ディープラーニングを取り入れた人工知能** - 特徴量と呼ばれる変数を自動的に学習し、高精度な分類・認識が可能。画像認識、自然言語処理など、データ内の複雑なパターンを深層学習するモデルが含まれる。  

- **人工知能の歴史**  
  「人工知能」という言葉は1956年、アメリカで開催されたダートマス会議で、ジョン・マッカーシーが使用したことにより誕生した。

### 人工知能分野で議論される問題

- **トイプロブレム**  
  現実世界の複雑な問題をコンピュータで扱えるように簡略化したもの。たとえば、迷路問題など現実の課題を単純化し、コンピュータ上でシミュレーションする。

- **フレーム問題**  
  今しようとしていることに関係のある事柄だけを選び出す難しさ。ジョン・マッカーシーとパトリック・ヘイズが1969年に提唱し、特に状況が変化する環境で必要な情報を選択する際に問題となる。

- **チューリングテスト**  
  アラン・チューリングが提唱。人間がコンピュータと会話し、相手がコンピュータだと気づけなければ、そのコンピュータには知能があると判断する。

- **ELIZA**  
  1960年代にジョセフ・ワイゼンバウムが開発したプログラムで、精神科セラピストを模倣し、相手の発言パターンに応じて返答する。

- **強いAI・弱いAI**  
  ジョン・サールが1980年に提唱した概念。  
  - **強いAI**: 適切にプログラムされたコンピュータは人間が心を持つのと同様に心を持つ。  
  - **弱いAI**: 実際に心を持たず、有用な道具であれば十分とされる。  

- **中国語の部屋**  
  チューリングテストに合格するAIでも、知能の有無は証明されないとする議論。部屋内の人は中国語の意味を理解せずに、ルールに従って中国語を処理できるが、理解しているわけではないという例え。

- **シンボルグラウンディング問題**  
  記号とその対象がどう結びつくかという問題。スティーブン・ハルナッドが提唱し、言語処理や認識の根本的な課題となる。

---

## 人工知能をめぐる動向

### 探索と推論

- **探索木**  
  コンピュータで処理するための形式。例えば、チェスのようなゲームで可能な手を木構造として表現し、解決策を探る際に役立てる。

- **幅優先探索**  
  出発地点に近いノード順に探索し、最短距離で解にたどり着く。メモリを多く使うが、必ず最短解を見つけられる。

- **深さ優先探索**  
  行けるところまで探索し、行き止まりになったら戻る。メモリ消費が少ないが、見つけた解が最短とは限らない。

- **ハノイの塔**  
  3本のポールに異なる大きさの円盤を並べ替える問題。ルールに従い最小手数で移動する解法を探索する。

- **Mini-Max法とαβ法**  
  **Mini-Max法**は、自分が有利になるように進め、相手の番では相手も同じ戦略を取ると仮定。  
  **αβ法**は、不要な探索を省き効率を高める。

- **モンテカルロ法**  
  ランダムにシミュレーションし、複数回プレイアウトして勝率を計算する。特にゲームAIで使われる。

### 知識表現とエキスパートシステム

- **ELIZA**  
  初期の人工知能で、あらかじめ設定されたパターンと一致する相手の発言に応じて返答する。

- **エキスパートシステム**  
  特定分野の知識を取り込み、その分野のエキスパートのように振る舞うプログラム。例として**MYCIN**は、血液中のバクテリア診断支援のために500のルールを活用する。

- **意味ネットワーク**  
  「概念」をノード、「関係」をリンクで表す構造。心理学から取り入れられ、知識の表現方法として活用される。

- **オントロジー**  
  言葉やその意味、関係性を形式化し、知識の共有に役立てる試み。エキスパートシステムの知識ベースの開発と保守が難しいため、この研究が進められた。

- **Cycプロジェクト**  
  一般常識をすべてコンピュータに取り込むプロジェクト。オントロジーの構築と一般常識の知識共有が目的。

- **データマイニングとウェブマイニング**  
  ビッグデータやウェブから知識を引き出す手法で、パターンや傾向を分析する。

- **IBM Watson**  
  IBMが開発したAIで、クイズ番組「ジョパディ！」に参加し優勝。膨大なデータをもとに推論し、回答する。

### 機械学習

- **機械学習**  
  人工知能のプログラム自身がデータから学習する仕組み
  サンプルデータを通してデータに潜むパターンを学習する
  サンプルデータの数が多ければ多いほど望ましい学習結果が得られる

- **特徴量**
  注目すべきデータの特徴を量的に表したもの 

- **次元の呪い**
  データの特徴が増えると、適切な学習を行うために必要なデータ量が著しく増加する傾向があること
  データの次元に見合ったデータ量がないと、データが不足している部分の学習が困難になるために起きる現象

- **ビッグデータ**
  インターネットの成長とともに蓄積された大容量のデータ

- **レコメンデーションエンジン**
  ユーザーの好みを推測する

- **スパムフィルタ**
  迷惑メールを検出する

### ディープラーニング

- **ニューラルネットワーク**
  機械学習の1つで、生物の神経回路を真似することで学習を実現しようとするもの

- **深層学習**
  深く多層化したニューラルネットワークを使って、データに潜む特徴を自動的に学習する手法
  ニューラルネットワークを多層化すること自体は難しくない
  しかし多層化したニューラルネットワーク全体を学習させる方法は、1986年に**誤差逆伝播法**という手法を提唱するまで広く知られていなかった

- **ネオコグニトロン**
  1979年に福島邦彦が発表した生物の視覚系の神経回路を模倣したニューラルネットワーク

- **LeNet**
  1989年、ヤンルカンはネオコグニトロンと同等なアイデアを採用した「畳み込みニューラルネットワーク」の構造を**LeNet**と名付け、そのニューラルネットワークの学習に誤差逆伝播法利用することを提案し、現在の画像認識ニューラルネットワークの基礎を築いた

- **ILSVRC**
  画像認識の精度を競い合う競技会
  2012年、トロント大学のジェフリーヒントンが率いるSuperVisionが圧倒的な勝利を収めた
  この競技会では、画像に移っているものが何なのかをコンピュータが推測する課題が与えられ、正解率を競い合う
  この時に開発されたニューラルネットワークのモデルは**AlexNet**と呼ばれる

- **LLM**
  大量言語データを学習する能力を持つ、大規模なニューラルネットワーク
  与えられた大量の文章を学習することで、一般的な言語の構造、文法、語彙などの基本を学びます
  これを**事前学習**と呼ぶ
  しかし、**事前学習**だけでは、学習した文章を単純に再現するだけになってしまう
  それだけでは、論理的な回答を生成したり、不適切な発言を避けたりすることを学んでいないため、人間が望ましいと考えるAIになりません
  そこで、**ファインチューニング**と呼ばれる学習を追加し、特定のタスクや応用分野に焦点を当てた訓練を行うことで、文脈を理解して論理的かつ適切な回答を生成する能力を向上させる

## 機械学習の概要

### 教師あり学習

- **教師あり学習**
  与えられたデータを基に、そのデータがどんなパターンになるのかを識別予測する
  連続値を予測する問題のことを回帰問題という
  離散値を予測する問題のことを分類問題という

- **線形回帰**
  データの分布があったときに、そのデータに最も当てはまる直線を考えるというもの
  線形回帰に正則化項を加えた手法として**ラッソ回帰**、**リッジ回帰**がある
  1種類だけ入力だけを用いて行う回帰分析を単回帰分析、複数種類の入力を用いる場合はを重回帰分析という

- **ロジスティック回帰**
  回帰問題ではなく、分類問題に用いる手法であることに注意
  シグモイド関数という関数をモデルの出力に用いる
  任意の値を0から1の間に写像するシグモイド関数を用いることによって、与えられたデータが正例になるか、負例（0）になるかの確率が求まる
  閾値を設定することでデータを2種類に分割する

- **ソフトマックス関数**
  各種類の出力値をそれぞれ0から1の間、および出力値の合計が1になるような出力を行う関数。

- **ランダムフォレスト**
  決定木を用いる手法
  複数の決定木を作成し、各決定木で用いる特徴量をランダムに抽出することで特徴量の組み合わせ問題に対応する
  バギングの中で決定木を用いている手法

- **ブートストラップサンプリング**
  学習に用いるデータも全データを使うのではなく、それぞれの決定木に対してランダムに一部のデータを取り出して学習に用いること

- **アンサンブル学習**
  複数のモデルを学習させること

- **バギング**
  全体から一部のデータを用いて複数のモデルを用いて学習する方法

- **ブースティング**
  **バギング**と同様、複数のモデルを学習さえる
  **バギング**では複数のモデルを並列に作成しましたが、**ブースティング**では直列に作成
  逐次的にモデルを作成する

- **AdaBoost**
  直列につないだモデルを順番に学習していく際、直前のモデルが誤認識してしまったデータの重みを大きくする
  一方正しく認識できたデータの重みを小さくする
  これを繰り返すことによって誤認識したデータを有セイン的に正しく分類できるようにモデルを学習する
  そして最終的に複数のモデルを1つのモデルとして統合する

- **勾配ブースティング**
  データに重みづけをする代わりに、前のモデルの予測誤差を関数として捉え、それを最小化するように逐次的にモデルの学習を進めるというアプローチ
  **XGBoost**というアルゴリズムによって拘束に学習計算をすることができる

- **サポートベクターマシン**
  高度な数学手理論に支えられた手法でる
  ディープラーニングが考えられる以前は機械学習において最も人気のあった手法の1つ
  異なるクラスの各データ点の距離が最大となるような境界線を求めることで、パターン分類を行う
  この距離を最大化することをマージン最大化という

- **カーネル関数**
  SVMでは、データをあえて高次元に写像することで、その写像後の空間で線形分類できるようにするというアプローチがとられた
  この写像に用いられる関数のことをカーネル関数という
  またその際、計算が複雑にならないようにするテクニックのことを**カーネルトリック**という
- **自己回帰モデル（AR）**
  一般的に回帰問題に適用される手法ですが、対象とするデータに大きな特徴がある
  それはこのモデルが対象とするのは時系列データであるということである
- **ベクトル自己回帰モデル**
  入力が複数種類の場合入力はベクトルになる
  この時の自己回帰モデルを**ベクトル自己回帰モデル**という

### 教師なし学習

- **教師なし学習**
  教師あり学習は入力と出力がセットとなったデータを用いるが、教師なし学習で用いるデータには出力がない
  入力データがもつ構造、特徴が対象となる
  
- **階層なしクラスタリング（K-means法）**
  データをk個のグループに分けることを目的としている
  元のデータからグループ構造を見つけ出し、それぞれをまとめる
  グループのことを**クラスタ**という

- **階層ありクラスタリング**
  クラスタの階層構造を求める手法
  代表的な手法にウォード法や最短距離法などがある
- **ウォード法**
  各データの平方和が小さい順にクラスタを作っていくことで階層構造を作る
  最短距離法は最も距離が近い2つのデータを選びそれらを1つのクラスタにまとめることで階層構造を作る
- **デンドログラム**
  各クラスタは樹形図で表すことができ、これが階層構造を示しているに他なりません。
  この樹形図のことを**デンドログラム**という
- **主成分分析**
  データの特徴量間の関係性、すなわち相関を分析することでデータの構造をつかむ手法
  特に特徴量の数が多い場合に用いられ、相関をもつ多数の特徴量から相関のない少数の特徴量へと次元削減すること主たる目的となる

- **特異値分解(Singular Value Decomposition , SVD)**
  次元削減の手法
  主に文章データを扱う場合によく用いられる
- **多次元尺度構成法(Multi-Dimensional Scaling , MDS)**
  次元削減の手法
  データの次元を2次元まで削減することによって可視化を行う手法
- **t-SNE(t-distributed Stochastic Neifghbor Embedding)**
  データの次元を2、3次元まで削減することによって可視化を行う手法
- **協調フィルタリング**
  レコメンデーションに用いられる手法の一つ
  考え方は「対象ユーザーは買っていないが、似ているユーザーは買っている商品を推薦する」というもの
  ユーザー間の類似度を定義することで、類似度の高いユーザーが購入済みの商品を推薦することが可能
- **コールドスタート問題**
  協調フィルタリングは事前にある程度参考できるデータがない限り、推薦を行うことができないこと
- **コンテンツベースフィルタリング**
  商品側に何かしらの特徴量を付与し特徴が似ている商品を推薦する
  対象のユーザーのデータさえあれば推薦を行うことができるので、コールドスタート問題を回避することができる
- **トピックモデル**
  k-means法やウォード法と同様クラスタリングを行うモデルですが、データを一つのクラスタに分類するk-means法などと異なり、複数のクラスタにデータを分類するのが特徴
  代表的な手法に**潜在的ディレクトリ配分法(latenet Dirichlet allocation , LDA)**があり、トピックモデルと言えばこのLDAを指すことが多い

### 強化学習

- **強化学習**
  行動を学習する仕組み
  ある環境下で、目的とする報酬を最大化するためにはどのような行動をとっていけばいいかを学習していく
- **バンディットアルゴリズム**
  強化学習では将来の累積報酬が最大となるような行動を求める必要がある
  一連の行動の組み合わせは無数にあるのでどこまでの行動の選択肢を考えるべきかが大きな課題となる
  ここで用いられる考え方が活用(exploitation)と探索(exploration)
  活用とは「現在知っている情報の中から報酬を最大となるような行動を選ぶ」
  探索とは「現在知っている情報以外の情報を獲得するために行動を選ぶ」
  活用と探索のバランスを取りましょうというもので**ε- greedy方策(epsilon-greedy policy)**や**UCB方策**などが具体的な手法
- **ε- greedy方策(epsilon-greedy policy)**
  基本的には活用、すなわち報酬が最大となる行動選択するが、一定確率εで探索、すなわちランダムな行動を選択するもの

- **UCB方策**
  期待値の高い選択を選ぶのを基本戦略としつつ、それまで試した回数が少ない行動は優先的に選択するというもの

- **マルコフ性**
  現在の状態S1から将来状態S2遷移する確率は、現在の状態にのみ依存し、それより過去の状態には一切依存しないという性質

- **価値関数**
  最適な方策を直接求める代わりに、状態や行動の「価値」を設定し、その価値が最大となるように学習をするアプローチ
  方策は**ε‐greedy方策**などを用いることにし、その下で、ある状態や行動によって得られる将来の累積報酬をその状態、行動の価値とすれば、価値が最大となる行動が求まり、適切な行動をとれるようになる
  具体的には、それぞれの価値を表す関数である**状態価値関数**、および**行動価値関数**を導入する。
  これらのうち大事なのが行動価値関数で、単純に価値関数と言った場合、行動価値関数を指します。
  式の文字から価値関数のことをQ値ともよび、Q値を最適化できれば、適切な行動が選択できるようになる

- **Q学習**
  Q値を最適化する手法にはQ学習やSARSAがあります。

- **方策勾配法**
  方策をあるパラメータで表される関数とし、（累積報酬の期待値が最大となるように）そのパラメータを学習していくアプローチ

- **REINFORCE**
  方策勾配法ベースの手法
  AlphaGoにも活用されている
- **Actor-Critic**
  価値関数ベース及び方策勾配ベースの考え方を組み合わせたアプローチ
  行動を決めるActor（行動器）と方策を評価するCritic（評価器）から成っているのが名前の由来

### モデルの選択と評価

- **交差検証**
  モデルの評価は未知のデータに対しての予測能力を見ることが適切
  未知のデータは文字通り未知なので準備することができない
  そのため手元にあるデータから疑似的に未知のデータを作り出すことになる
  手元にある全データを学習用のデータと評価用のデータにランダムに分割して評価する
  このようにデータを分割して評価することを交差検証と呼ぶ

- **ホールドアウト検証**
  事前にデータを訓練データとテストデータに分割する
- **k―分割交差検証**
  訓練データ・テストデータの分割を複数回行い、それぞれで学習評価を行う
- **正解率(accuracy)**
  全データ中、どれだけ予測が当たったかの割合
  $$accuracy={\frac{TP+TN}{TP+TN+FP+FN}}$$
- **適合率(precision)**
  予測が正の中で、実際に正であったものの割合
  $$precision={\frac{TP}{TP+FP}}$$ 
- **再現率‘(recall)**
  実際に正であるものの中で、正だと予測できた割合
  $$recall={\frac{TP}{TP+FN}}$$
- **F値(F measure)**
  適合率と再現率の調和平均
  適合率のみあるいは再現率のみで判断すると、予測が偏っているときも値が高くなってしまうのでF値を用いることも多い
  $$F measure={\frac{2*precision*recall}{precision+recall}}$$
- **過学習　過剰適合**
  訓練データのみに最適化されすぎている状態
- **ROC曲線**
- 横軸にFRP、縦軸にTRPを取り、閾値を0から1に変化させていった際の両者の値をプロットしたものを指す
  $$TRP={\frac{TP}{TP+FN}}$$
  $$FRP={\frac{FP}{FP+TN}}$$

## ディープラーニングの概要

### ニューラルネットワークとディープラーニング

- **単純パーセプトロン**  
  ニューラルネットワークはニューロンの特徴を再現できないかと試した手法
  複数の特徴量（入力）を受け取り、1つの値を出力する
  単純なニュートラルネットワークのモデル
- **入力層と出力層**
  ニューラルネットワークは人間の脳の神経回路が層構造になっている（と考えられている）のにならい、入力を受け取る部分を**入力層**、出力する部分を**出力層**と表現する
  入力層における各ニューロンと、出力層におけるニューロンの間のつながりは重みで表され、どれだけの電気信号を伝えるかを調整する
  そして、出力が0か1の値をとるようにすることで、正例と負例の分類を可能にしている
  0から1の値をとるようにする場合はシグモイド関数を用いる
- **活性化関数**
  層の間をどのように伝播させるかを調整する関数
- **多層パーセプトロン**
  単純パーセプトロンが実際の予測で使われるケースはほとんどない
  入力層‐出力層のつながりではまだまだモデルが単純すぎて、複雑な問題に対応することができない
  そこで考えられたのが、入力層‐出力層以外にさらに層を追加するというアプローチ
  層を追加したモデルを多層パーセプトロンと呼ぶ
  非線形分類も行うことができる
- **隠れ層**
  入力層と出力層の間に追加された層
- **パラメータ**
  機械学習の手法にはデータを正しく予測するためには最適化すべき値が存在する
  ニューラルネットワークにおいては重みの値が代表例となるが、こうした学習によって求める値のこと
- **CPUとGPU**
  **CPU**はコンピュータ全般の作業を処理する役割を担う
  様々な種類のタスクを順番に処理していくことに長けている
  **GPU**は画像処理に関する演算を担
  映像や3DCGなどを処理する場合は同一画像に同じ演算を一挙に行うことが求められる
- **GPGPU**
  画像以外の目的での使用に最適化されたGPUのこと
- **TPU**
  Google社が早くから独自のチップ開発を進めており、**TPU(Tensor Processing Unit)**という名前で公開している
  その名の通りテンソル計算処理に最適化されている
  機械学習に特化した演算処理装置

- **バーニーおじさんのルール**
  データ量の目安となる経験則
  モデルのパラメータ数の10倍のデータ数が必要

### 誤差関数

- **平均二乗誤差関数**
  モデルの予測性能の評価に用いられた平均二乗誤差関数ですが、これらはそのまま誤差ｋ何数としても用いられ、平均二乗誤差関数とよぶ
  訓練データを用いてこの関数を最小化する＝モデルの予測値と正解値との誤差が小さくなるということなので、平均二乗誤差関数の最小化を考えることがモデルの予測性能の向上につながる
  予測誤差をそのまま表していると言っても良い関数なので、予測性能の評価の時と同様、分類問題・回帰問題にかかわらず用いることができる
  ただし分類問題では別の誤差関数が用いられることも多く、実際は回帰問題の誤差関数として用いられる
  
- **交差エントロピー誤差関数**
  交差エントロピーは2つの確率分布がどれくらい異なるかを定式化したもの
  これらを誤差関数とし手利用したもの
  分類問題で最も用いられる誤差関数

- **深層距離学習**
  距離学習は文字通りデータ間の距離を測るためのアプローチ
  データ間の類似度を推定するための手法で、顔認証や類似データの検索など様々な分野に応用されている
  これをディープラーニングに応用した手法を**深層距離学習**とよぶ
  **iamese Network**や**Triplet Network**が有名でそれぞれ入力が2つのデータを用いるか、3つのデータを用いるかの違いがある
  そして前者では**Contrastive Loss**、後者では**Triplet Loss**と呼ぶ誤差関数を用いる
- **生成モデルにおける誤差**
  生成モデルが目指すのは与えられたデータがどのような確率分布に基づいているかを見つけること
  つまり生成モデルは「今観測できているデータはなんらかの確率分布に基づいて生成されているはずだ」という考えに基づいて、そのデータを生成している確率分布をモデル化しようと試みている
  データ分布になるべく近いモデル分布を求めることが目的なので、両者の分布のズレを誤差関数として定義すればよい
  確率分布のズレを測る指標として用いられるのが、**カルバック・ライブラー情報量**と**イェンゼン・シャノン情報量**になる
  それぞれ**KLダイバージェンス**と**JSダイバージェンス**と略記される
- **深層生成モデル**
  生成モデルにディープラーニングを活用したモデル
- **変分オートエンコーダ(variational autoencoder, VAE)**
  深層生成モデルのひとうつ
  カルバック・ライブラー情報量をベースとした誤差関数が最適化計算に用いられる

  ### 正則化

- **正則化**
  ディープラーニングを含む機械学習の最大の敵であると言っても過言ではない過学習ですが、その対応策も色々とかんがえており、総じて正則化と呼ぶ
  正則化のなかでも広く用いられる手法が誤差関数にペナルティ項を課すというもの
  誤差関数に制約条件を課すことによって、モデルのパラメータが取り得る範囲を制限するのがこのアプローチ

- **L1正則化**
  名前に含まれているL1、L2は数学用語のノルムに対応している
  **L1ノルム**は重みなどモデルパラメータの各成分の絶対値の和
  **特徴**：L1正則化　一部のパラメータの値をゼロにすることで、不要なパラメータを削減することができる
  L1正規化を適用した手法を**ラッソ解析**
- **L2正則化**
　**L2ノルム**は各成分の2乗和の平方根なので距離に相当する
　**特徴**　パラメータの大きさに応じてゼロに近づけることで、汎化された滑らかなモデルを得ることができる
　**L2正規化**を適用した手法を**リッジ解析**

- **ドロップアウト**
  モデルの学習の行い方を工夫することで過学習を防ぐアプローチで、名前の通り学習の際にランダムにニューロンを除外するもの
  ネットワークから学習のエポックごとに除外するニューロンを変えることで毎回形の異なるネットワークで学習を行う
  ドロップアウトは内部的にアンサンプル学習を行っている

### 最適化手法

- **勾配降下法**
  モデルの学習とは**誤差関数**の**最小化**を目指すこと
  関数の最小化問題であるため誤差関数を各層の重みなどモデルのパラメータで微分してゼロになるような値を求めればよいわけだが、問題が発生する
  一般的にニューラルネットワークで解こうとするような問題は入力の次元が多次元にわたるので、最適なパラメータが解析計算では求まらない
  そこで、実際のモデルの学習では、解析的に解を求めにいくのではなく、アルゴリズムを用いて最適解を探索する、というアプローチをとる
  ここで用いる手法のことを勾配降下法と呼ぶ
  **勾配降下法**は機械学習に限らず様々な分野において最適化計算に用いる手法で名前の通り「勾配に沿って降りていくことで解を探索する」手法

- **バッチ勾配降下法**
  全データの予測誤差の総和を用いて更新式の計算をすることを**バッチ勾配降下法**と呼ぶ
  バッチとはデータの塊を表し、一回の更新計算にすべてのデータを用いるためにこのような名前がついている
  バッチを用いて学習を行うので**バッチ勾配降下法**による学習を**バッチ学習**という

- **確率的勾配降下法**
  理論的には**バッチ勾配降下法**できちんと最適解の探索ができるのですがディープラーニングの学習においては問題が生じる場合がある
  特に発生しやすい問題としては「扱うデータ数が大きい・扱うデータの次元数が大きいために、全データの誤差を計算するためのメモリが足りなくなる」というもの
  そこで「訓練データをシャッフルしたうえで一つランダムに抽出、そのデータの予測誤差だけを用いて更新式を計算する」というアプローチをとることがある
  このアプローチのことを確率的勾配降下法と呼ぶ
  **確率的勾配降下法**を用いた学習を**オンライン学習**という

- **ミニバッチ勾配降下法**
  **バッチ勾配降下法**・**確率勾配降下法**いずれも一長一短ありますが、両者のちょうど間をとった手法が**ミニバッチ勾配降下法**になる
  全データをいくつかのデータセットに分割し、そのデータセットごとに更新計算を行う
  バッチは全データを指しましたが、それをいくつかの小さいデータセットに分割するので**ミニバッチ**という
  各データセット内のデータ数のことをバッチサイズという
  **ミニバッチ勾配降下法**を用いた学習のことを**ミニバッチ学習**と呼ぶ

- **学習率の調整**
  **勾配降下法**によって最適解の探索ができるようになりましたが、実は探索がいつもうまくいくとは限りません
  適切な最適解が得られないケースが多々あります
  勾配降下法は「見せかけの最適化」であるかどうかを見抜くことができません　
  みせかけの解のことを**局所最適解**、本当の最適解のことを**大域最適解**という
  **局所最適解**を防ぐ方法として、まず考えられるのは**学習率**の値を大きく設定すること

- **学習率**
  勾配に沿ってどれくらい進むかを調整するもの
  学習率が大きいままだと、最適解を飛び越えて探索し続けてしまうという問題が起こりやすくなってしまうので、適切なタイミングで学習率を小さくすることが必要

- **鞍点**
  ある次元から見れば極小であるものの、別の次元から見ると極大となってしまっているもののこと

- **モーメンタム**
  ディープラーニングが考えられる以前に、鞍点問題にどう対処すべきかについて考えられていた
  1990年代に提唱されたモーメンタム呼ばれる手法は、まさしく物理でいう考え方を適用したもので、最適化の進行方向に学習を加速させることで、学習の停滞を防ぐもの

  古いものから**Adagrad**,**Adadelta**,**RMSprop**,**Adam**,**AdaBound**,**AMSBound**などがある
  アルゴリズムの詳細はもちろんそれぞれ異なるが、いずれも土台となっているのはモーメンタムと同じで、どの方向に学習を加速すればいいかを考えたものになる

- **早期終了**
  勾配降下法にy労最適化において、学習率の調整以外にもう一つ厄介な問題がある
  それは過学習である
  過度に最適解の探索をすることは過学習につながる
  そこで用いられる手法が早期終了です
  名前の通り学習を早めに打ち切るもの
  学習が進むにつれてテストデータに対する誤差関数の値は右肩上がりになってしまう
  その上がり始めが過学習のし始めと考え、その時点で学習を止めれば、そこが最適解が得られたところ

- **ノーフリーランチ定理**
  あらゆる問題で性能のよい汎用最適化戦略は理論上不可能であること

- **二十降下現象**
  一度テストデータに対する誤差が増えた後、再度誤差が減っていくという現象
- **ハイパーパラメータチューニング**
  モデルのパラメータは勾配降下法によって最適化できるようになりましたが、どんなモデルを学習するにせよ、ハイパーパラメータは自分で設定しなければなりません
  ニューラルネットワークを何層にするか、各層のニューロン数をいくつにするか、ドロップアウトはどれくらいにするか、L1正則化L2正則化をどれくらい効かせるかなど
  ハイパーパラメータ値を調整していくことをハイパーパラメータチューニングと呼ぶ

- **グリッドサーチ**
  調整したい（複数の）ハイパーパラメータの値の候補を明示的にいくつか指定し、その候補全ての組み合わせに対して学習・評価を行うことで一番良いパラメータを抽出する
  ある程度ハイパーパラメータの値が絞られているときに用いる

- **ランダムサーチ**
  値の候補そのものを指定するのではなく、値の取り得る範囲を指定する
  その範囲の中でなに頭の確率分布に基づいた乱数を発生させ、その乱数をハイパーパラメータとして実験を行う
  見当がついていない場合でも取り得る値の範囲を広めに取っておけばある程度探索できるのが特徴

  他にもベイズ最適化や遺伝的アルゴリズムといった手法を用いてハイパーパラメータ最適化を目指すアプローチもありますがパラメータの最適化と同様、探索に時間がかかってしまうのが難点

### 誤差逆伝播法

- **誤差逆伝播法**
- 勾配降下法の更新式はパラメータごとに計算するのでネットワークがふかくなればなるほど、探索すべきパラメータの数は膨大になっていく
- そこで複数のパラメータに対して微分を効率よく求めるために考えられたのが誤差逆伝播法である
  誤差逆伝播法では、ネットワークの各層において、その層に伝播してきた値には自分より前の層のパラメータの値が含まれていることに注目し、微分計算を再利用することを考える
  そのために合成関数の微分あるいは連鎖率とよばれる微分の公式を用いる
- **信用割当問題**
  誤差逆伝播法の導入によるメリットは計算の効率化だけでなく、どのニューロンが予測結果に寄与している・していないかを判別できるようになったことも挙げられる
  これは機械学習においてよく指摘される、「モデルのどの部分がその予測結果をもたらしているのかが分からない」という信用割当問題を解決できているといえる
  ただし「なぜ」その予測結果が得られるのかについては関係ない

- **勾配消失問題、勾配爆発問題**
  誤差逆伝播法の導入により効率よくニューラルネットワークの学習を行うことができるようになり、モデルを多層化することも容易になった
  これにより、新たに出てきた問題が勾配消失問題や勾配爆発問題である
  名前の通り誤差を逆伝播する過程で勾配値が小さくなりすぎてしまう、あるいは大きくなりすぎてしまう問題のことで、いずれも勾配を用いた最適解の探索できなくなってしまい、学習の失敗の要因となる
- **正則化**
- **正則化**
- **正則化**
- **正則化**
- **正則化**
- **正則化**
- **正則化**
- **正則化**
- **正則化**
- 




　